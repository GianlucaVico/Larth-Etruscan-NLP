{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Methods:\n",
    "* Replace only Etruscan proper names -> for LM\n",
    "* Replace both Etruscan and English proper names -> for MT\n",
    "* Use category / POS tags instead of actual words\n",
    "\n",
    "Abbreviations are used only for proper names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import utils\n",
    "import random\n",
    "import re\n",
    "from collections import defaultdict, deque\n",
    "from typing import Tuple, List, Dict, Optional, Union\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>City</th>\n",
       "      <th>Year - From</th>\n",
       "      <th>Year - To</th>\n",
       "      <th>Etruscan</th>\n",
       "      <th>Translation</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ETP 192</td>\n",
       "      <td>Ager Tarquiniensis</td>\n",
       "      <td>275.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>cleusinas  laris  larisal  clan</td>\n",
       "      <td>laris cleusinas, son of laris.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cr 2.20</td>\n",
       "      <td>Caere</td>\n",
       "      <td>675.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>mi karkanas thahvna</td>\n",
       "      <td>i (am) the container of karkana</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cm 2.46</td>\n",
       "      <td>Campania</td>\n",
       "      <td>500.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>mi e.i. mi.n.pi capi mi numar   thevru.c.l.na...</td>\n",
       "      <td>'don't take me. i (am) nunar. (i am the proper...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ETP 269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>625.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>mini muluvanice tetana ve.l.ka.s.na.s. veleli...</td>\n",
       "      <td>tetana velkasnas gave me to velellia.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ta 3.2</td>\n",
       "      <td>Tarquinia</td>\n",
       "      <td>580.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>itun turuce vene.l a.telinas. tinas dlniiaras</td>\n",
       "      <td>venel atelinas dedicated this (vase) to the so...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5815</th>\n",
       "      <td>20926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reithu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5819</th>\n",
       "      <td>20982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ecnatnial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>21003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ivnii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>21065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>marces</td>\n",
       "      <td>mr-marces</td>\n",
       "      <td>1A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>21077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mi larthias urial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7139 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                City  Year - From  Year - To  \\\n",
       "0     ETP 192   Ager Tarquiniensis        275.0      250.0   \n",
       "1     Cr 2.20                Caere        675.0      650.0   \n",
       "2     Cm 2.46             Campania        500.0      450.0   \n",
       "3     ETP 269                  NaN        625.0      600.0   \n",
       "4      Ta 3.2            Tarquinia        580.0      580.0   \n",
       "...        ...                 ...          ...        ...   \n",
       "5815     20926                 NaN          NaN        NaN   \n",
       "5819     20982                 NaN          NaN        NaN   \n",
       "5822     21003                 NaN          NaN        NaN   \n",
       "5830     21065                 NaN          NaN        NaN   \n",
       "5832     21077                 NaN          NaN        NaN   \n",
       "\n",
       "                                               Etruscan  \\\n",
       "0                      cleusinas  laris  larisal  clan    \n",
       "1                                  mi karkanas thahvna    \n",
       "2      mi e.i. mi.n.pi capi mi numar   thevru.c.l.na...   \n",
       "3      mini muluvanice tetana ve.l.ka.s.na.s. veleli...   \n",
       "4        itun turuce vene.l a.telinas. tinas dlniiaras    \n",
       "...                                                 ...   \n",
       "5815                                             reithu   \n",
       "5819                                          ecnatnial   \n",
       "5822                                              ivnii   \n",
       "5830                                             marces   \n",
       "5832                                  mi larthias urial   \n",
       "\n",
       "                                            Translation  key  \n",
       "0                        laris cleusinas, son of laris.  NaN  \n",
       "1                       i (am) the container of karkana  NaN  \n",
       "2     'don't take me. i (am) nunar. (i am the proper...  NaN  \n",
       "3                 tetana velkasnas gave me to velellia.  NaN  \n",
       "4     venel atelinas dedicated this (vase) to the so...  NaN  \n",
       "...                                                 ...  ...  \n",
       "5815                                                NaN    1  \n",
       "5819                                                NaN    2  \n",
       "5822                                                NaN   1C  \n",
       "5830                                          mr-marces   1A  \n",
       "5832                                                NaN    1  \n",
       "\n",
       "[7139 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = pd.read_csv(\"../Etruscan.csv\", index_col=0)\n",
    "docs[\"Etruscan\"] = docs[\"Etruscan\"].apply(lambda x: utils.replace(x, utils.to_latin))\n",
    "docs[\"Translation\"] = docs[\"Translation\"].apply(lambda x: np.nan if x is np.nan else x.lower().strip())\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Etruscan</th>\n",
       "      <th>Translations</th>\n",
       "      <th>POS</th>\n",
       "      <th>Is inferred</th>\n",
       "      <th>Is suffix</th>\n",
       "      <th>Abbreviation of</th>\n",
       "      <th>Suffix indexes</th>\n",
       "      <th>city name</th>\n",
       "      <th>place name</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>1st pert</th>\n",
       "      <th>2nd pert</th>\n",
       "      <th>1st pers</th>\n",
       "      <th>2nd pers</th>\n",
       "      <th>3rd pers</th>\n",
       "      <th>pl</th>\n",
       "      <th>gen</th>\n",
       "      <th>abl</th>\n",
       "      <th>pert</th>\n",
       "      <th>TAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>isa</td>\n",
       "      <td>((True, the),)</td>\n",
       "      <td>def art nom</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>isha</td>\n",
       "      <td>((True, the),)</td>\n",
       "      <td>def art nom</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>((True, and),)</td>\n",
       "      <td>enclitic conj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ishla</td>\n",
       "      <td>((True, the),)</td>\n",
       "      <td>def art 2nd gen</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cle</td>\n",
       "      <td>((True, the),)</td>\n",
       "      <td>dem pro loc</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>fleres</td>\n",
       "      <td>((True, divine spirit), (True, divinity))</td>\n",
       "      <td>1st gen</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>flerthrce</td>\n",
       "      <td>()</td>\n",
       "      <td>past act</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>fratuce</td>\n",
       "      <td>((False, incised),)</td>\n",
       "      <td>past act</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>frontac</td>\n",
       "      <td>((True, of lightning),)</td>\n",
       "      <td>nom acc</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>[---]e</td>\n",
       "      <td>()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1122 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Etruscan                               Translations              POS  \\\n",
       "0           isa                             ((True, the),)      def art nom   \n",
       "1          isha                             ((True, the),)      def art nom   \n",
       "2             x                             ((True, and),)    enclitic conj   \n",
       "3         ishla                             ((True, the),)  def art 2nd gen   \n",
       "4           cle                             ((True, the),)      dem pro loc   \n",
       "...         ...                                        ...              ...   \n",
       "1117     fleres  ((True, divine spirit), (True, divinity))          1st gen   \n",
       "1118  flerthrce                                         ()         past act   \n",
       "1119    fratuce                        ((False, incised),)         past act   \n",
       "1120    frontac                    ((True, of lightning),)          nom acc   \n",
       "1121     [---]e                                         ()              NaN   \n",
       "\n",
       "      Is inferred  Is suffix Abbreviation of Suffix indexes  city name  \\\n",
       "0           False       True             NaN            NaN        NaN   \n",
       "1           False       True             NaN            NaN        NaN   \n",
       "2           False       True             NaN            NaN        NaN   \n",
       "3           False       True             NaN            NaN        NaN   \n",
       "4           False       True             NaN            NaN        NaN   \n",
       "...           ...        ...             ...            ...        ...   \n",
       "1117        False      False             NaN            NaN        NaN   \n",
       "1118        False      False             NaN            NaN        NaN   \n",
       "1119        False      False             NaN            NaN        NaN   \n",
       "1120        False      False             NaN            NaN        NaN   \n",
       "1121        False      False             NaN            NaN        NaN   \n",
       "\n",
       "      place name  name  ...  1st pert  2nd pert  1st pers  2nd pers  3rd pers  \\\n",
       "0            NaN   NaN  ...       0.0       0.0       NaN       NaN       NaN   \n",
       "1            NaN   NaN  ...       0.0       0.0       NaN       NaN       NaN   \n",
       "2            NaN   NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "3            NaN   NaN  ...       0.0       0.0       NaN       NaN       NaN   \n",
       "4            NaN   NaN  ...       0.0       0.0       NaN       NaN       NaN   \n",
       "...          ...   ...  ...       ...       ...       ...       ...       ...   \n",
       "1117         NaN   NaN  ...       0.0       0.0       NaN       NaN       NaN   \n",
       "1118         NaN   NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "1119         NaN   NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "1120         NaN   NaN  ...       0.0       0.0       NaN       NaN       NaN   \n",
       "1121         NaN   NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "      pl    gen    abl   pert   TAG  \n",
       "0    NaN  False  False  False   ADP  \n",
       "1    NaN  False  False  False  PRON  \n",
       "2    NaN  False  False  False   PRT  \n",
       "3    NaN   True  False  False   DET  \n",
       "4    NaN  False  False  False   ADP  \n",
       "...   ..    ...    ...    ...   ...  \n",
       "1117 NaN   True  False  False  NOUN  \n",
       "1118 NaN  False  False  False  VERB  \n",
       "1119 NaN  False  False  False  VERB  \n",
       "1120 NaN  False  False  False   ADJ  \n",
       "1121 NaN  False  False  False   NaN  \n",
       "\n",
       "[1122 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = utils.load_pos(\"../ETP_POS.csv\")\n",
    "vocab[\"Etruscan\"] = vocab[\"Etruscan\"].apply(lambda x: utils.replace(x, utils.to_latin))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_columns = [\"city name\", \"place name\", \"name\", \"epithet\", \"theo\", \"cogn\", \"prae\", \"nomen\"]\n",
    "\n",
    "def is_proper_name(df: pd.DataFrame, include_abbreviation: bool=False) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Check if the entry is a proper name.\n",
    "\n",
    "    Args:\n",
    "        df: POS dataframe\n",
    "        include_abbreviation: whether to include abbreviated names in the name mask\n",
    "    Returns:\n",
    "        Bool mask that selects the proper names\n",
    "    \"\"\"\n",
    "    mask = df[name_columns].apply(pd.Series.any, axis = 1)\n",
    "    if not include_abbreviation:\n",
    "        mask = mask & df[\"Abbreviation of\"].isna()  # If NA -> not an abbreviation\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_index(df: pd.DataFrame) -> Tuple[List[int], Dict[Tuple[bool], int]]:\n",
    "    \"\"\"\n",
    "    Compute the indexes for the proper names. Names with the same characteristics \n",
    "    have the same index.\n",
    "\n",
    "    Args:\n",
    "        df: dataframe with the category columns of the proper names (i.e., exclude \"Translation\", \"POS\", etc..., keep \"nom\", \"acc\", etc...)\n",
    "    Return:\n",
    "        Tuple with list of indexes and dictionary with tuple describing the name and the index.\n",
    "    \"\"\"\n",
    "    indexes = []\n",
    "    map_ = {}\n",
    "    current_index = -1\n",
    "    for row in df.iloc:\n",
    "        tmp = tuple((row >= 0.5).to_list())        \n",
    "        candidate = map_.get(tmp)\n",
    "        if candidate is None: # New item\n",
    "            current_index += 1\n",
    "            indexes.append(current_index)\n",
    "            map_[tmp] = current_index\n",
    "        else: # Not new\n",
    "            indexes.append(candidate)\n",
    "    \n",
    "    return indexes, map_\n",
    "\n",
    "def expand_index(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Expand the translations: a single translation for each row.\n",
    "\n",
    "    Args:\n",
    "        df: dataframe with Etruscan, Translations and Index\n",
    "    Returns:\n",
    "        Dataframe with expanded translations\n",
    "    \"\"\"\n",
    "    tmp = []\n",
    "    for row in df.iloc:\n",
    "        if len(row[\"Translations\"]) == 0:\n",
    "            tmp.append((row[\"Etruscan\"], np.nan, row[\"Index\"]))\n",
    "        else:\n",
    "            for t in row[\"Translations\"]:\n",
    "                tmp.append((row[\"Etruscan\"], t[1], row[\"Index\"]))\n",
    "    return pd.DataFrame.from_records(tmp, columns=[\"Etruscan\", \"Translations\", \"Index\"])\n",
    "\n",
    "def create_index(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series, Dict[Tuple[bool], int]]:\n",
    "    \"\"\"\n",
    "    Create the index dataframe.\n",
    "\n",
    "    Args:\n",
    "        df: POS dataframe\n",
    "    Returns:\n",
    "        Index dataframe, name mask, index map\n",
    "    \"\"\"\n",
    "    name_mask = is_proper_name(df)\n",
    "    indexes, map_ = compute_index(df[name_mask][utils.tags])\n",
    "\n",
    "    index_df = pd.DataFrame({\"Etruscan\": df[name_mask][\"Etruscan\"], \"Translations\": df[name_mask][\"Translations\"], \"Index\": indexes}).reset_index(drop=True)\n",
    "    index_df = expand_index(index_df)\n",
    "    return index_df, name_mask, map_\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Etruscan</th>\n",
       "      <th>Translations</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capue</td>\n",
       "      <td>in capua</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enash</td>\n",
       "      <td>ena</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>veldthi</td>\n",
       "      <td>velca</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vipshl</td>\n",
       "      <td>vipsa</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kamarte</td>\n",
       "      <td>kamarta</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>fulu.s.la</td>\n",
       "      <td>fulu</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>fufle</td>\n",
       "      <td>fufle</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>[---]aninal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>[----]aninalc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>[---]pnal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Etruscan Translations  Index\n",
       "0            capue     in capua      0\n",
       "1            enash          ena      1\n",
       "2          veldthi        velca      2\n",
       "3           vipshl        vipsa      2\n",
       "4          kamarte      kamarta      0\n",
       "..             ...          ...    ...\n",
       "508      fulu.s.la         fulu     13\n",
       "509          fufle        fufle     35\n",
       "510    [---]aninal          NaN     12\n",
       "511  [----]aninalc          NaN     12\n",
       "512      [---]pnal          NaN     12\n",
       "\n",
       "[513 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_df, name_mask, map_ = create_index(vocab)\n",
    "print(\"Indexes:\", index_df[\"Index\"].max()+1)\n",
    "index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_df_to_map(\n",
    "        index_df: pd.DataFrame, \n",
    "        lang:str = \"et\", \n",
    "        name_to_index:bool=True\n",
    "        ) -> Union[Dict[str, int], Dict[Tuple[str, str], int], Dict[int, List[str]], Dict[int, List[Tuple[str,str]]]]:\n",
    "    \"\"\"\n",
    "    Convert the index dataframe to a dictionary for efficiency\n",
    "\n",
    "    Args:\n",
    "        index_df: index dataframe\n",
    "        lang: language of the map (values in [\"et\", \"eng\", \"bi\"])\n",
    "        name_to_index: if True the output maps a name to an index. Otherwise, it maps an index to a list of names\n",
    "    Returns:\n",
    "        Dictionary\n",
    "    \"\"\"\n",
    "    if lang == \"et\":\n",
    "        col = \"Etruscan\"\n",
    "    elif lang == \"eng\":\n",
    "        col = \"Translations\"\n",
    "    elif lang == \"bi\":\n",
    "        col = [\"Etruscan\", \"Translations\"]\n",
    "    index_df = index_df.dropna()\n",
    "    if name_to_index:\n",
    "        if lang == \"bi\":\n",
    "            # Dict: (et name, eng name): index            \n",
    "            return dict(zip(list(index_df[col].itertuples(index=False, name=None)), index_df[\"Index\"]))\n",
    "        else:\n",
    "            # Dict: name: index\n",
    "            return dict(zip(index_df[col].to_list(), index_df[\"Index\"]))\n",
    "    else:\n",
    "        d = defaultdict(list)\n",
    "        if lang == \"bi\":\n",
    "            for row in index_df.iloc:\n",
    "                d[row[\"Index\"]].append(tuple(row[col]))\n",
    "        else:\n",
    "            for row in index_df.iloc:\n",
    "                d[row[\"Index\"]].append(row[col])\n",
    "        return d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Etruscan names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_text_single(text: str, index_df: Union[pd.DataFrame, Dict[str, int]], fmt: str=\"§{}§\") -> str:\n",
    "    \"\"\"\n",
    "    Replace proper name with an index.\n",
    "\n",
    "    Args:\n",
    "        text: text to process\n",
    "        index_df: index dataframe\n",
    "        fmt: string to format the indexes (e.g., \"§0§\", \"§10§\")\n",
    "    Return:\n",
    "        Text with index instead of the proper names.\n",
    "    \"\"\"    \n",
    "    if isinstance(index_df, pd.DataFrame):\n",
    "        index_df = index_df_to_map(index_df, \"et\", True)\n",
    "\n",
    "    for name, index in index_df.items():        \n",
    "        r = re.compile(fr\"\\b{name}\\b\")\n",
    "        text = r.sub(fmt.format(index), text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single(\n",
    "        text: str, \n",
    "        index_df: Union[pd.DataFrame, Dict[int, List[str]]],\n",
    "        fmt: str=\"§{}§\", \n",
    "        index_threshold:Tuple[int, int] = (8, 20),\n",
    "        max_replacements:Tuple[int, int, int]=(3, 2, 1),\n",
    "        rng: random.Random = None\n",
    "        ) -> List[str]:        \n",
    "    \"\"\"\n",
    "    Replace the index with all the compatible proper names.\n",
    "\n",
    "    Args:\n",
    "        text: text to process\n",
    "        index_df: index dataframe\n",
    "        etruscan: wheter it is an Etruscan text. English otherwise\n",
    "        fmt: string to format the indexes (e.g., \"§0§\", \"§10§\")\n",
    "        index_threshold: use a different number of replacements based on the number of indexes\n",
    "        max_replacements: up to this number of replacements for each index\n",
    "        rng: random number generator used to select the replacements\n",
    "    Return:\n",
    "        List of text with proper names instead of indexes.    \n",
    "\n",
    "    Note: it might generate duplicated entries\n",
    "    \"\"\"    \n",
    "    if rng is None:\n",
    "        rng = random.Random(0)\n",
    "\n",
    "    if isinstance(index_df, pd.DataFrame):\n",
    "        index_df = index_df_to_map(index_df, \"et\", False)\n",
    "    # RE to find the marks\n",
    "    mark = re.compile(fmt.format(r\"(?P<index>[0-9]+)\"))\n",
    "    \n",
    "    # Results, list of strings\n",
    "    out = []\n",
    "\n",
    "    # Strore string that could have marks in it\n",
    "    q = deque()\n",
    "    q.append(text)\n",
    "\n",
    "    n = len(mark.findall(text))\n",
    "    # print(n)\n",
    "    \n",
    "    if n > index_threshold[1]:\n",
    "        threshold = max_replacements[2]\n",
    "    elif n > index_threshold[0]:\n",
    "        threshold = max_replacements[1]\n",
    "    else:\n",
    "        threshold = max_replacements[0]\n",
    "\n",
    "    while len(q) != 0:\n",
    "        # Get next string\n",
    "        t = q.popleft()        \n",
    "        match_ = mark.search(t)\n",
    "        \n",
    "        if match_ is None: # All substitution are done                   \n",
    "            out.append(t)\n",
    "        else: # Still some mark to replace\n",
    "            index = int(match_.group(\"index\"))\n",
    "            this_mark = re.compile(match_.group())  # e.g., §0§ instead of §.*§\n",
    "            # candidates = index_df[index_df[\"Index\"] == index][col].to_list()\n",
    "            candidates = index_df[index]\n",
    "            \n",
    "            # Too many raplacements: select few\n",
    "            if len(candidates) > threshold:                \n",
    "                # candidates = rng.choice(candidates, threshold)\n",
    "                candidates = rng.sample(candidates, k=threshold)\n",
    "\n",
    "            for c in candidates:\n",
    "                q.append(this_mark.sub(c, t, 1)) # Replace only the first match\n",
    "    \n",
    "    # Remove duplicates      \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_etruscan(\n",
    "        docs: pd.DataFrame, \n",
    "        index_df: pd.DataFrame, \n",
    "        index_threshold:Tuple[int, int] = (8, 20),\n",
    "        max_replacements:Tuple[int, int, int]=(3, 2, 1),\n",
    "        seed:int=0\n",
    "    ) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Generate new Etruscan texts.\n",
    "\n",
    "    Args:\n",
    "        docs: dataframe with Etruscan texts. Column: \"Etruscan\"\n",
    "        index_df: index dataframe\n",
    "        index_threshold: use a different number of replacements based on the number of indexes\n",
    "        max_replacements: up to this number of replacements for each index\n",
    "    Return:\n",
    "        Tuple with generated texts and marked texts\n",
    "    \"\"\"\n",
    "    rng = random.Random(seed)\n",
    "    out = [None] * len(docs) # List of lists\n",
    "\n",
    "    name_to_index = index_df_to_map(index_df, \"et\", True)\n",
    "    index_to_name = index_df_to_map(index_df, \"et\", False)\n",
    "\n",
    "    # Add the indexes\n",
    "    marked = docs[\"Etruscan\"].progress_apply(lambda x: mark_text_single(x, name_to_index)).to_list()\n",
    "    \n",
    "    # mark = re.compile(r\"§(?P<index>[0-9]+)§\")\n",
    "    \n",
    "    # Replace the indexes\n",
    "    for i, j in enumerate(tqdm(marked)): \n",
    "        out[i] = generate_single(j, index_to_name, index_threshold=index_threshold, max_replacements=max_replacements, rng=rng)\n",
    "\n",
    "    # Flatten the output\n",
    "    out = [j for i in out for j in i]\n",
    "    out = list(set(out))\n",
    "    return out, marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7139 [00:00<?, ?it/s]/tmp/ipykernel_8808/3783577247.py:18: FutureWarning: Possible set difference at position 6\n",
      "  r = re.compile(fr\"\\b{name}\\b\")\n",
      "/tmp/ipykernel_8808/3783577247.py:18: FutureWarning: Possible set difference at position 8\n",
      "  r = re.compile(fr\"\\b{name}\\b\")\n",
      "/tmp/ipykernel_8808/3783577247.py:18: FutureWarning: Possible set difference at position 4\n",
      "  r = re.compile(fr\"\\b{name}\\b\")\n",
      "100%|██████████| 7139/7139 [00:03<00:00, 1932.75it/s]\n",
      "100%|██████████| 7139/7139 [00:03<00:00, 2071.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original texts: 7139\n",
      "Generated texts: 82013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gen, mark = generate_etruscan(docs, index_df)\n",
    "print(\"Original texts:\", len(docs))\n",
    "print(\"Generated texts:\", len(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6578 [00:00<?, ?it/s]/tmp/ipykernel_8808/3783577247.py:18: FutureWarning: Possible set difference at position 6\n",
      "  r = re.compile(fr\"\\b{name}\\b\")\n",
      "/tmp/ipykernel_8808/3783577247.py:18: FutureWarning: Possible set difference at position 8\n",
      "  r = re.compile(fr\"\\b{name}\\b\")\n",
      "/tmp/ipykernel_8808/3783577247.py:18: FutureWarning: Possible set difference at position 4\n",
      "  r = re.compile(fr\"\\b{name}\\b\")\n",
      "100%|██████████| 6578/6578 [00:03<00:00, 2047.70it/s]\n",
      "100%|██████████| 6578/6578 [00:01<00:00, 6386.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original texts: 6578\n",
      "Generated texts: 5884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 561/561 [00:00<00:00, 1561.36it/s]\n",
      "100%|██████████| 561/561 [00:02<00:00, 229.90it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original texts: 561\n",
      "Generated texts: 76144\n",
      "Masked texts: 561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use only CIEP\n",
    "gen_ciep, _ = generate_etruscan(docs.dropna(subset=\"key\"), index_df)\n",
    "print(\"Original texts:\", len(docs.dropna(subset=\"key\")))\n",
    "print(\"Generated texts:\", len(gen_ciep))\n",
    "\n",
    "# Use only ETP\n",
    "gen_etp, masked = generate_etruscan(docs[docs[\"key\"].isna()], index_df)\n",
    "print(\"Original texts:\", len(docs[docs[\"key\"].isna()]))\n",
    "print(\"Generated texts:\", len(gen_etp))\n",
    "print(\"Masked texts:\", len(masked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Etruscan and English names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_text_paired(\n",
    "        pair: Tuple[str, str],\n",
    "        pair_index: Optional[Dict[str,int]] = None,\n",
    "        fmt: str=\"§{}§\") -> str:\n",
    "    \"\"\"\n",
    "    Replace proper name with an index.\n",
    "\n",
    "    Args:\n",
    "        text: text to process\n",
    "        pair_index_df: index dataframe\n",
    "        fmt: string to format the indexes (e.g., \"§0§\", \"§10§\")\n",
    "    Return:\n",
    "        Text with index instead of the proper names.\n",
    "    \"\"\"    \n",
    "    if isinstance(pair_index, pd.DataFrame):\n",
    "        pair_index = index_df_to_map(pair_index, \"bi\", name_to_index=True)\n",
    "\n",
    "    for (name_et, name_eng), index in pair_index.items():\n",
    "        if name_et is not np.nan and name_eng is not np.nan and len(name_et) != 0 and len(name_eng) != 0:            \n",
    "            r_et = re.compile(fr\"\\b{name_et}\\b\")\n",
    "            r_eng = re.compile(fr\"\\b{name_eng}\\b\")\n",
    "\n",
    "            if len(r_et.findall(pair[0])) == len(r_eng.findall(pair[1])) != 0:                               \n",
    "                pair = (\n",
    "                    r_et.sub(fmt.format(index), pair[0]),\n",
    "                    r_eng.sub(fmt.format(index), pair[1])\n",
    "                )\n",
    "    return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paired(\n",
    "        pair: Tuple[str, str],         \n",
    "        pair_index: Union[pd.DataFrame,Dict[str,int]],\n",
    "        fmt: str=\"§{}§\",\n",
    "        index_threshold:Tuple[int, int] = (8, 20),\n",
    "        max_replacements:Tuple[int, int, int]=(3, 2, 1),\n",
    "        rng: random.Random = None\n",
    "        ) -> List[str]:        \n",
    "    \"\"\"\n",
    "    Replace the index with all the compatible proper names.\n",
    "\n",
    "    Args:\n",
    "        text: text to process\n",
    "        index_df: index dataframe\n",
    "        etruscan: wheter it is an Etruscan text. English otherwise\n",
    "        fmt: string to format the indexes (e.g., \"§0§\", \"§10§\")\n",
    "        index_threshold: use a different number of replacements based on the number of indexes\n",
    "        max_replacements: up to this number of replacements for each index\n",
    "        rng: random number generator used to select the replacements\n",
    "    Return:\n",
    "        List of text with proper names instead of indexes.    \n",
    "\n",
    "    Note: it might generate duplicated entries\n",
    "    \"\"\"    \n",
    "    if rng is None:\n",
    "        rng = np.random.RandomState(0)\n",
    "\n",
    "    if isinstance(pair_index, pd.DataFrame):\n",
    "        pair_index = index_df_to_map(pair_index, \"bi\", False)\n",
    "    # RE to find the marks\n",
    "    mark = re.compile(fmt.format(r\"(?P<index>[0-9]+)\"))\n",
    "    \n",
    "    # Results, list of strings\n",
    "    out = []\n",
    "\n",
    "    # Strore string that could have marks in it\n",
    "    q = deque()\n",
    "    q.append(pair)\n",
    "\n",
    "    n = len(mark.findall(pair[0]))\n",
    "    # print(n)\n",
    "    \n",
    "    if n > index_threshold[1]:\n",
    "        threshold = max_replacements[2]\n",
    "    elif n > index_threshold[0]:\n",
    "        threshold = max_replacements[1]\n",
    "    else:\n",
    "        threshold = max_replacements[0]\n",
    "\n",
    "    while len(q) != 0:\n",
    "        # Get next string\n",
    "        t = q.popleft()        \n",
    "        match_et = mark.search(t[0])\n",
    "        # match_eng = mark.search(t[1])\n",
    "        \n",
    "        if match_et is None: # All substitution are done                   \n",
    "            out.append(t)\n",
    "        else: # Still some mark to replace\n",
    "            index = int(match_et.group(\"index\"))\n",
    "            this_mark = re.compile(match_et.group())  # e.g., §0§ instead of §.*§\n",
    "            # candidates = index_df[index_df[\"Index\"] == index][col].to_list()\n",
    "            candidates = pair_index[index]\n",
    "            \n",
    "            # Too many raplacements: select few\n",
    "            if len(candidates) > threshold:                \n",
    "                # candidates = rng.choice(candidates, threshold, replace=False)\n",
    "                candidates = rng.sample(candidates, k=threshold)\n",
    "\n",
    "            for c in candidates:\n",
    "                q.append((\n",
    "                    this_mark.sub(c[0], t[0], 1),\n",
    "                    this_mark.sub(c[1], t[1], 1)\n",
    "                )) # Replace only the first match\n",
    "    \n",
    "    # Remove duplicates      \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_translations(\n",
    "        docs: pd.DataFrame, \n",
    "        index_df: pd.DataFrame, \n",
    "        index_threshold:Tuple[int, int] = (8, 20),\n",
    "        max_replacements:Tuple[int, int, int]=(3, 2, 1),\n",
    "        seed:int=0\n",
    "    ) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Generate new Etruscan texts.\n",
    "\n",
    "    Args:\n",
    "        docs: dataframe with Etruscan texts. Column: \"Etruscan\", \"Translations\"\n",
    "        index_df: index dataframe\n",
    "        index_threshold: use a different number of replacements based on the number of indexes\n",
    "        max_replacements: up to this number of replacements for each index\n",
    "    Return:\n",
    "        Tuple with generated texts and marked texts\n",
    "    \"\"\"\n",
    "    docs = docs.dropna(subset=[\"Etruscan\", \"Translation\"])\n",
    "    rng = random.Random(seed)\n",
    "    out = [None] * len(docs) # List of lists\n",
    "\n",
    "    name_to_index = index_df_to_map(index_df, \"bi\", True)\n",
    "    index_to_name = index_df_to_map(index_df, \"bi\", False)\n",
    "\n",
    "    # Add the indexes\n",
    "    marked = docs.progress_apply(lambda x: mark_text_paired((x[\"Etruscan\"], x[\"Translation\"]), name_to_index),axis=1).to_list()\n",
    "    \n",
    "    # mark = re.compile(r\"§(?P<index>[0-9]+)§\")\n",
    "    \n",
    "    # Replace the indexes\n",
    "    for i, j in enumerate(tqdm(marked)):         \n",
    "        out[i] = generate_paired(j, index_to_name, index_threshold=index_threshold, max_replacements=max_replacements, rng=rng)\n",
    "\n",
    "    # Flatten the output\n",
    "    out = [j for i in out for j in i]\n",
    "    out = list(set(out))\n",
    "    return out, marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2891 [00:00<?, ?it/s]/tmp/ipykernel_3531/2194514593.py:20: FutureWarning: Possible set difference at position 8\n",
      "  r_et = re.compile(fr\"\\b{name_et}\\b\")\n",
      "100%|██████████| 2891/2891 [00:56<00:00, 51.16it/s]\n",
      "100%|██████████| 2891/2891 [00:00<00:00, 38068.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original texts: 7139\n",
      "Generated texts: 14022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gen, mark = generate_translations(docs, index_df)\n",
    "print(\"Original texts:\", len(docs))\n",
    "print(\"Generated texts:\", len(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2652 [00:00<?, ?it/s]/tmp/ipykernel_3531/2194514593.py:20: FutureWarning: Possible set difference at position 8\n",
      "  r_et = re.compile(fr\"\\b{name_et}\\b\")\n",
      "100%|██████████| 2652/2652 [00:50<00:00, 52.32it/s]\n",
      "100%|██████████| 2652/2652 [00:00<00:00, 190646.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original texts: 6578\n",
      "Generated texts: 2382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/239 [00:00<?, ?it/s]/tmp/ipykernel_3531/2194514593.py:20: FutureWarning: Possible set difference at position 8\n",
      "  r_et = re.compile(fr\"\\b{name_et}\\b\")\n",
      "100%|██████████| 239/239 [00:04<00:00, 50.95it/s]\n",
      "100%|██████████| 239/239 [00:00<00:00, 3298.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original texts: 561\n",
      "Generated texts: 11641\n",
      "Masked texts: 239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use only CIEP\n",
    "gen_ciep, _ = generate_translations(docs.dropna(subset=\"key\"), index_df)\n",
    "print(\"Original texts:\", len(docs.dropna(subset=\"key\")))\n",
    "print(\"Generated texts:\", len(gen_ciep))\n",
    "\n",
    "# Use only ETP\n",
    "gen_etp, masked = generate_translations(docs[docs[\"key\"].isna()], index_df)\n",
    "print(\"Original texts:\", len(docs[docs[\"key\"].isna()]))\n",
    "print(\"Generated texts:\", len(gen_etp))\n",
    "print(\"Masked texts:\", len(masked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_alpha(t):\n",
    "    return re.sub(r\"[^a-zA-Z ]\", \"\", t)\n",
    "\n",
    "def make_pos_train_set(vocab):\n",
    "    words = vocab[\"Etruscan\"].apply(only_alpha)\n",
    "    tags = vocab[\"TAG\"]\n",
    "    return [[(i,j)] for i,j in zip(words, tags)]\n",
    "\n",
    "def simple_tokenizer(x):\n",
    "    tmp = [i.strip() for i in re.split(r\"[:• ]\", x.lower())]\n",
    "    return [i for i in tmp if len(i) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_none(tagger, docs):\n",
    "    toks = docs[\"Etruscan\"].apply(simple_tokenizer)\n",
    "    tot = 0\n",
    "    none = 0\n",
    "    for i in toks:\n",
    "        tags = tagger.tag(i)\n",
    "        tot += len(tags)\n",
    "        for j in tags:\n",
    "            if j[1] is None or j[1] is np.nan:\n",
    "                none += 1\n",
    "    return none, tot\n",
    "\n",
    "def tag(tagger, docs):\n",
    "    toks = docs[\"Etruscan\"].apply(simple_tokenizer)\n",
    "    return [tagger.tag(i) for i in toks]    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trained Unigram tagger: size=959, backoff=6.77%, pruning=0.00%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cleusinas', 'NOUN'),\n",
       " ('laris', 'NOUN'),\n",
       " ('larisal', 'NOUN'),\n",
       " ('clan', 'NOUN')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = nltk.tag.UnigramTagger(make_pos_train_set(vocab), verbose=True) # Use the entire vocab, just for testing\n",
    "tagger.tag(simple_tokenizer(docs.iloc[0][\"Etruscan\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot tokens: 10340\n",
      "None tags: 8132\n",
      "None ratio: 0.7864603481624758\n"
     ]
    }
   ],
   "source": [
    "none, tot = count_none(tagger, docs)\n",
    "print(\"Tot tokens:\", tot)\n",
    "print(\"None tags:\", none)\n",
    "print(\"None ratio:\", none/tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--ETP--\n",
      "Tot tokens: 2546\n",
      "None tags: 1039\n",
      "None ratio: 0.40809112333071484\n",
      "--CIEP--\n",
      "Tot tokens: 7794\n",
      "None tags: 7093\n",
      "None ratio: 0.9100590197587888\n"
     ]
    }
   ],
   "source": [
    "print(\"--ETP--\")\n",
    "none, tot = count_none(tagger, docs[docs[\"key\"].isna()])\n",
    "print(\"Tot tokens:\", tot)\n",
    "print(\"None tags:\", none)\n",
    "print(\"None ratio:\", none/tot)\n",
    "\n",
    "print(\"--CIEP--\")\n",
    "none, tot = count_none(tagger, docs.dropna(subset=\"key\"))\n",
    "print(\"Tot tokens:\", tot)\n",
    "print(\"None tags:\", none)\n",
    "print(\"None ratio:\", none/tot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test other taggers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brill: no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBL train (fast) (seqs: 7139; tokens: 10340; tpls: 2; min score: 0; min acc: None)\n",
      "Finding initial useful rules...\n",
      "    Found 924 useful rules.\n",
      "\n",
      "           B      |\n",
      "   S   F   r   O  |        Score = Fixed - Broken\n",
      "   c   i   o   t  |  R     Fixed = num tags changed incorrect -> correct\n",
      "   o   x   k   h  |  u     Broken = num tags changed correct -> incorrect\n",
      "   r   e   e   e  |  l     Other = num tags changed incorrect -> incorrect\n",
      "   e   d   n   r  |  e\n",
      "------------------+-------------------------------------------------------\n",
      "  24  24   0   0  | None->NOUN if Pos:None@[-1] & Word:a@[0]\n",
      "  20  20   0   0  | None->NOUN if Pos:None@[-1] & Word:clan@[0]\n",
      "  20  20   0   0  | None->NOUN if Pos:None@[-1] & Word:v@[0]\n",
      "  20  20   0   0  | None->PRON if Pos:None@[-1] & Word:mi@[0]\n",
      "  20  20   0   0  | None->VERB if Pos:None@[-1] & Word:turce@[0]\n",
      "  14  14   0   0  | None->NOUN if Pos:None@[-1] & Word:arnthial@[0]\n",
      "  14  14   0   0  | None->NOUN if Pos:None@[-1] & Word:avils@[0]\n",
      "  14  14   0   0  | None->NOUN if Pos:None@[-1] & Word:larthial@[0]\n",
      "  12  12   0   0  | None->NOUN if Pos:None@[-1] & Word:shuthi@[0]\n",
      "  12  12   0   0  | None->PRT if Pos:None@[-1] & Word:c@[0]\n",
      "  11  11   0   0  | None->ADV if Pos:None@[-1] & Word:thui@[0]\n",
      "  10  10   0   0  | None->NOUN if Pos:None@[-1] & Word:lart@[0]\n",
      "  10  10   0   0  | None->NOUN if Pos:None@[-1] & Word:lautnitha@[0]\n",
      "  10  10   0   0  | None->PRON if Pos:None@[-1] & Word:in@[0]\n",
      "  10  10   0   0  | None->VERB if Pos:None@[-1] & Word:lupu@[0]\n",
      "  10  10   0   0  | None->VERB if Pos:None@[-1] & Word:mulu@[0]\n",
      "   9  15   6   3  | None->NOUN if Pos:VERB@[-1]\n",
      "  16  54  38  18  | None->NOUN if Pos:NOUN@[-1]\n",
      "   9   9   0   0  | None->NOUN if Pos:None@[-1] & Word:avil@[0]\n",
      "   9   9   0   0  | None->NOUN if Pos:None@[-1] & Word:laris@[0]\n"
     ]
    }
   ],
   "source": [
    "nltk.tbl.Template._cleartemplates()\n",
    "templates = [nltk.tbl.Template(nltk.tag.brill.Pos([-1])), nltk.tbl.Template(nltk.tag.brill.Pos([-1]), nltk.tag.brill.Word([0]))]\n",
    "trainer = nltk.tag.BrillTaggerTrainer(nltk.tag.RegexpTagger([]), templates, trace=3) # As doc says, UnigramTagger does not work\n",
    "brill_tagger = trainer.train(tag(tagger, docs), min_score=0, max_rules=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPLATE STATISTICS (TRAIN)  2 templates, 20 rules)\n",
      "TRAIN (  10340 tokens) initial  2585 0.7500 final:  2311 0.7765\n",
      "#ID | Score (train) |  #Rules     | Template\n",
      "--------------------------------------------\n",
      "001 |   249   0.909 |  18   0.900 | Template(Pos([-1]),Word([0]))\n",
      "000 |    25   0.091 |   2   0.100 | Template(Pos([-1]))\n",
      "\n",
      "UNUSED TEMPLATES (0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "brill_tagger.print_template_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cleusinas', None), ('laris', 'NOUN'), ('larisal', None), ('clan', 'NOUN')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brill_tagger.tag(simple_tokenizer(docs[\"Etruscan\"].iloc[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trained Unigram tagger: size=7237, backoff=0.00%, pruning=0.00%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cleusinas', 'NOUN'),\n",
       " ('laris', 'NOUN'),\n",
       " ('larisal', 'NOUN'),\n",
       " ('clan', 'NOUN')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger = nltk.tag.BigramTagger(tag(tagger, docs), verbose=True)\n",
    "bigram_tagger.tag(simple_tokenizer(docs.iloc[0][\"Etruscan\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trained Unigram tagger: size=60, backoff=93.30%, pruning=95.75%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cleusinas', 'NOUN'),\n",
       " ('laris', 'NOUN'),\n",
       " ('larisal', 'NOUN'),\n",
       " ('clan', 'NOUN')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affix_tagger = nltk.tag.AffixTagger(tag(tagger, docs), verbose=True, backoff=tagger, min_stem_length=1)\n",
    "affix_tagger.tag(simple_tokenizer(docs.iloc[0][\"Etruscan\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trained Unigram tagger: size=7497, backoff=0.00%, pruning=0.00%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cleusinas', 'NOUN'),\n",
       " ('laris', 'NOUN'),\n",
       " ('larisal', 'NOUN'),\n",
       " ('clan', 'NOUN')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_tagger = nltk.tag.TrigramTagger(tag(tagger, docs), verbose=True)\n",
    "trigram_tagger.tag(simple_tokenizer(docs.iloc[0][\"Etruscan\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(multi_case=True):\n",
    "    cols = utils.tags.copy()\n",
    "    if not multi_case:\n",
    "        cases = [\"gen\", \"abl\", \"pert\"]\n",
    "        for i in [\"1st\", \"2nd\"]:\n",
    "            for j in cases:\n",
    "                cols.remove(f\"{i} {j}\")\n",
    "        cols += cases    \n",
    "    return cols\n",
    "\n",
    "def make_category_train_set(vocab, multi_case=True):\n",
    "    cols = get_categories(multi_case)\n",
    "    words = vocab[\"Etruscan\"].apply(only_alpha)\n",
    "    tags = vocab[cols].itertuples(index=False, name=None)\n",
    "    return [[(i,j)] for i,j in zip(words, tags)]\n",
    "\n",
    "def category_description(cat: Tuple, to_dict:bool=False) -> Union[Dict[str, Union[float, bool]], str]:\n",
    "    if len(cat) == 54:\n",
    "        names = get_categories(multi_case=True)\n",
    "    elif len(cat) == 51:\n",
    "        names = get_categories(multi_case=False)\n",
    "    else:\n",
    "        raise Exception(\"Invalid category length\")\n",
    "    \n",
    "    d = dict(zip(names, cat))\n",
    "    if to_dict:\n",
    "        return d\n",
    "    else:\n",
    "        lines = [f\"{i}: {j}\" for i,j in d.items()]\n",
    "        return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trained Unigram tagger: size=959, backoff=14.53%, pruning=0.00%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cleusinas',\n",
       "  (nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan)),\n",
       " ('laris',\n",
       "  (nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan)),\n",
       " ('larisal',\n",
       "  (nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan)),\n",
       " ('clan',\n",
       "  (nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan,\n",
       "   nan))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_tagger = nltk.tag.UnigramTagger(make_category_train_set(vocab), verbose=True) # Use the entire vocab, just for testing\n",
    "cat_tagger.tag(simple_tokenizer(docs.iloc[0][\"Etruscan\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etruscan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "013aae73bde15ce377457fd8870d15060dc8e5f6ca43ae7bb0be23f3e535538f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
